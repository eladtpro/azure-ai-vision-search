# Vector Image Search using Azure OpenAI with Azure AI Search
![Diagram](/readme/diagram_vector_search.png)


In this article, we dive into the core functionalities of the azure-ai-vision-search repository, focusing on the ***search*** and ***vectorize*** methods in the [function_app.py](/function_app.py) file. These methods are pivotal in integrating Azure's AI services to perform vector image searches.


## Azure AI Search Schema

Below are Azure AI Search schema files that define the index, indexer, and skillset used to store and process image data for efficient search and retrieval. These files are used to configure the Azure AI Search service to work with the vector image search solution. 

#### 1. Index Definition 
* **File**: [vector-image-index-db.json](/artifacts/vector-image-index-db.json)  
* **Role**: Defines the structure and schema of the search index.  
* **Details**: Specifies the fields, their data types, and attributes (e.g., searchable, filterable) that will be used to store and retrieve the image metadata and embeddings.  

#### 2. Indexer Definition 
* **File**: [vector-image-indexer.json](/artifacts/vector-image-indexer.json)  
* **Role**: Configures how data from the data source (e.g., Azure Storage) is ingested into the search index.  
* **Details**: Specifies the data source, scheduling, and mapping of data fields from the source to the index. It handles the scanning of new images and updates the index accordingly.  

#### 3. Skillset Definition
* **File**: [vector-image-skillset.json](/artifacts/vector-image-skillset.json)  
* **Role**: Defines the AI enrichment pipeline to extract and transform information from the images before indexing.  
* **Details**: Specifies a series of cognitive skills (e.g., image recognition, OCR) that process the images and generate enriched data (e.g., tags, embeddings) used in the search index.  

These components work together to enable the ingestion, transformation, and indexing of image data, allowing efficient search and retrieval using Azure AI Search service, with **the indexer triggering the vectorize Azure Function for handling image embeddings**.



## The *vectorize* Method
The *vectorize* method is responsible for converting images into vector embeddings. This process involves several steps:

#### 1. HTTP Request Handling:
* The method is triggered by a POST request containing image URLs and other metadata.  
* The request body is parsed to extract the values needed for processing.  

#### 2. Image Embedding Generation:
* The ***vectorize_images*** function is called with the extracted values. This function processes each image URL by invoking the ***vectorize_image*** helper function.  
* Within ***vectorize_image***, a SAS token is created for secure access to the image stored in Azure Blob Storage.  
* The ***get_image_embeddings*** function from the helper module generates the embeddings using Azure's Computer Vision API. The embeddings are numerical representations capturing the semantic content of the images.
#### 3. Response Construction:

* The embeddings are assembled into a response payload.  
* The response is returned as a JSON object, making the embeddings available for downstream tasks such as indexing and searching.  

By leveraging Azure's Computer Vision API, the ***vectorize*** method transforms images into vectors. These vectors are numeric representations that encapsulate the images' visual features, making them suitable for similarity searches.  

#### Usage
```
# Example usage
image_urls = ["https://example.com/image1.jpg", "https://example.com/image2.jpg"]
embeddings = vectorize_images(image_urls)
print(embeddings)
```

## The *search* Method
The search method facilitates image similarity searches using vectors generated by the vectorize method. Here's how it works:

#### 1. HTTP Request Handling:
* The method is triggered by a POST request containing a query string and optional parameters like *max_images*.  

#### 2. Query Processing with OpenAI:
* The provided query is refined using the ***ask_openai*** function, which interacts with Azure OpenAI. This function rephrases the query to improve search accuracy.  
* The refined query is then converted into vector embeddings using the ***generate_embeddings_text*** function. This function utilizes Azure's Computer Vision API to generate text embeddings.  

#### 3. Vector Search Execution:
* A ***VectorizedQuery*** object is created, containing the query embeddings and parameters for the search.  
* The ***search_client*** performs a vector search on the image vectors stored in the Azure AI Search index. This search identifies images whose vector embeddings are most similar to the query embeddings.  

#### 4. Result Compilation:
* The search results are compiled into a response payload. For each result, a SAS token is generated for secure access to the image.
* The response is returned as a JSON object, containing the image URLs, titles, and search scores.  

The ***search*** method integrates Azure OpenAI and Azure AI Search to perform efficient and accurate image similarity searches. By converting textual queries into vector embeddings, it ensures that the search results are relevant and precise.

## Usage
```
# Example usage
query = "Find images of mountains"
search_results = search_images(query, max_images=5)
print(search_results)
```

## Azure Resources
The azure-ai-vision-search repository leverages several Azure services to enable vector image searches:
![Azure Resources](/readme/azure-resources.png)

## Conclusion
The ***vectorize*** and ***search*** methods in the azure-ai-vision-search repository exemplify the powerful integration of Azure's AI services. The ***vectorize*** method transforms images into vector embeddings, while the ***search*** method leverages these embeddings for similarity searches. Together, they enable a robust and efficient vector image search solution using **Azure OpenAI** and **Azure AI Search**.